{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "##############\n",
    "#  Packages  #\n",
    "##############\n",
    "import os\n",
    "import sys \n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from plotly.offline import plot\n",
    "import plotly.io as pio\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "#from umap import UMAP\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "pio.renderers = \"browser\"\n",
    "\n",
    "##################\n",
    "#      Imports   #\n",
    "##################\n",
    "root_path = Path(\"C:/Users/Charles/Desktop/MVA/GDA/Geom_stat/\")\n",
    "sys.path.insert(0, str(root_path))\n",
    "\n",
    "from utils_tda_and_clustering import (\n",
    "    homology_parquet_to_matrix_bootstraps,\n",
    "    make_pca_bootstraps,\n",
    "    get_clusters,\n",
    "    transform_gleason,\n",
    "    meta_clustering,\n",
    "    choose_representative_bootstrap,\n",
    "    get_meta_bootstraps\n",
    ")\n",
    "\n",
    "img_path = root_path.joinpath(\"raw_images\")\n",
    "saving_path = root_path.joinpath(\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [08:11<00:00,  4.92s/it]\n"
     ]
    }
   ],
   "source": [
    "base_name = \"b1\"\n",
    "base_path = str(saving_path.joinpath(f\"{base_name}.parquet\"))\n",
    "df_ident, bootstraps, original = homology_parquet_to_matrix_bootstraps(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_bootstraps, reduced_original, vars_explained = make_pca_bootstraps(bootstraps, original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.spatial.distance import pdist\n",
    "from gap_statistic import OptimalK\n",
    "\n",
    "def optimalK(reduced_bootstraps,  reduced_original, minClusters=2, maxClusters=10):\n",
    "    \"\"\"\n",
    "    Calculates KMeans optimal K using Gap Statistic \n",
    "    Params:\n",
    "        data: ndarry of shape (n_samples, n_features)\n",
    "        nrefs: number of sample reference datasets to create\n",
    "        maxClusters: Maximum number of clusters to test for\n",
    "    Returns: (gaps, optimalK)\n",
    "    \"\"\"\n",
    "    gaps = np.zeros((len(range(minClusters, maxClusters)),))\n",
    "    resultsdf = {}\n",
    "    for gap_index, k in enumerate(range(minClusters, maxClusters)):# Holder for reference dispersion results\n",
    "        refDisps = np.zeros(len(bootstraps))# For n references, generate random sample and perform kmeans getting resulting dispersion of each loop\n",
    "        for i,b in tqdm(enumerate(reduced_bootstraps)):\n",
    "\n",
    "            clustering_model = AgglomerativeClustering(n_clusters=k, metric='euclidean', linkage='ward')\n",
    "            clustering_model.fit(b[\"reduced\"])\n",
    "            clusters_indices = clustering_model.labels_\n",
    "\n",
    "            clusters = [[b[\"reduced\"][j] for j in range(len(clusters_indices)) if clusters_indices[j]==i] for i in range(k)]\n",
    "            \n",
    "            distances = []\n",
    "            for c in clusters:\n",
    "                D_c = np.sum(pdist(c, 'euclidean'))/(2*len(c))\n",
    "                distances.append(D_c)\n",
    "            \n",
    "            bootstrapDisp = np.sum(distances) # The value of W_k for one of our bootstraps\n",
    "            refDisps[i] = bootstrapDisp\n",
    "        \n",
    "        clustering_model = AgglomerativeClustering(n_clusters=k, metric='euclidean', linkage='ward')\n",
    "        clustering_model.fit(reduced_original[\"reduced\"])\n",
    "        clusters_indices = clustering_model.labels_\n",
    "        \n",
    "        clusters = [[reduced_original[\"reduced\"][j] for j in range(len(clusters_indices)) if clusters_indices[j]==i] for i in range(k)]\n",
    "        \n",
    "        distances = []\n",
    "        for c in clusters:\n",
    "            D_c = np.sum(pdist(c, 'euclidean'))/(2*len(c))\n",
    "            distances.append(D_c)\n",
    "        \n",
    "        origDisp = np.sum(distances)\n",
    "        \n",
    "        gap = np.mean(np.log(refDisps)) - np.log(origDisp)# Assign this loop's gap statistic to gaps\n",
    "        gaps[gap_index] = gap\n",
    "        \n",
    "        resultsdf[k] = gap\n",
    "    return (gaps.argmax() + minClusters, resultsdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimalK(reduced_bootstraps, reduced_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_bootstraps, clustered_original = get_clusters(reduced_bootstraps, reduced_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_tda_and_clustering import transform_gleason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gleason_bootstraps = transform_gleason(bootstraps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Charles\\Desktop\\MVA\\GDA\\Geom_stat\\notebook pour tests.ipynb Cell 9\u001b[0m line \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Charles/Desktop/MVA/GDA/Geom_stat/notebook%20pour%20tests.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m gleason_bootstraps:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Charles/Desktop/MVA/GDA/Geom_stat/notebook%20pour%20tests.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     clusters \u001b[39m=\u001b[39m clusters \u001b[39m+\u001b[39m b[\u001b[39m\"\u001b[39m\u001b[39mclusters\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Charles/Desktop/MVA/GDA/Geom_stat/notebook%20pour%20tests.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m gleason_points \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([b[\u001b[39m\"\u001b[39m\u001b[39mgleason_coords\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m gleason_bootstraps])\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m3\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "clusters = []\n",
    "for b in gleason_bootstraps:\n",
    "    clusters = clusters + b[\"clusters\"]\n",
    "gleason_points = np.array([b[\"gleason_coords\"] for b in gleason_bootstraps]).reshape(-1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_clusters_indices = meta_clustering(gleason_points)\n",
    "meta_clusters = [[clusters[k] for k in c] for c in meta_clusters_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_clusters_gleason_coords = [[gleason_points[k] for k in c] for c in meta_clusters_indices]\n",
    "representative_bootstrap = choose_representative_bootstrap(gleason_bootstraps, meta_clusters_gleason_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_bootstraps = get_meta_bootstraps(meta_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.spatial.distance import pdist\n",
    "from gap_statistic import OptimalK\n",
    "\n",
    "def optimalK_meta(data, n_bootstraps = 100, minClusters=1, maxClusters=10):\n",
    "    \"\"\"\n",
    "    Calculates KMeans optimal K using Gap Statistic \n",
    "    Params:\n",
    "        data: ndarry of shape (n_samples, n_features)\n",
    "        nrefs: number of sample reference datasets to create\n",
    "        maxClusters: Maximum number of clusters to test for\n",
    "    Returns: (gaps, optimalK)\n",
    "    \"\"\"\n",
    "    gaps = np.zeros((len(range(minClusters, maxClusters)),))\n",
    "    gaps_sds = np.zeros_like(gaps)\n",
    "    for gap_index, k in enumerate(range(minClusters, maxClusters)):# Holder for reference dispersion results\n",
    "        refDisps = np.zeros(n_bootstraps)# For n references, generate random sample and perform kmeans getting resulting dispersion of each loop\n",
    "        for i in range(n_bootstraps):\n",
    "\n",
    "            b = np.random.choice(len(data), len(data), replace=True)\n",
    "            b = data[b]\n",
    "\n",
    "            clustering_model = AgglomerativeClustering(n_clusters=k, metric='euclidean', linkage='ward')\n",
    "            clustering_model.fit(b)\n",
    "            clusters_indices = clustering_model.labels_\n",
    "\n",
    "            clusters = [[b[j] for j in range(len(clusters_indices)) if clusters_indices[j]==i] for i in range(k)]\n",
    "            \n",
    "            distances = []\n",
    "            for c in clusters:\n",
    "                D_c = np.sum(pdist(c, 'euclidean'))/(2*len(c))\n",
    "                distances.append(D_c)\n",
    "            \n",
    "            bootstrapDisp = np.sum(distances) # The value of W_k for one of our bootstraps\n",
    "            refDisps[i] = np.log(bootstrapDisp)\n",
    "        \n",
    "        clustering_model = AgglomerativeClustering(n_clusters=k, metric='euclidean', linkage='ward')\n",
    "        clustering_model.fit(data)\n",
    "        clusters_indices = clustering_model.labels_\n",
    "        \n",
    "        clusters = [[data[j] for j in range(len(clusters_indices)) if clusters_indices[j]==i] for i in range(k)]\n",
    "        \n",
    "        distances = []\n",
    "        for c in clusters:\n",
    "            D_c = np.sum(pdist(c, 'euclidean'))/(2*len(c))\n",
    "            distances.append(D_c)\n",
    "        \n",
    "        origDisp = np.sum(distances)\n",
    "        \n",
    "        gap = np.mean(refDisps) - np.log(origDisp)# Assign this loop's gap statistic to gaps\n",
    "        gaps[gap_index] = gap\n",
    "\n",
    "        gaps_sds[gap_index] = np.std(refDisps)\n",
    "        \n",
    "    return (gaps, gaps_sds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
